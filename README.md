# BERGEN-UP

>   New version of BERGEN (a.k.a BERGEN UPâœ¨)

[**BERGEN**](https://github.com/naver/bergen?tab=readme-ov-file) (*BEnchmarking Retrieval-augmented GENeration*) is a library designed to benchmark RAG systems with a focus on question-answering (QA) by **NAVER Labs**. It addresses the challenge of inconsistent benchmarking in comparing approaches and understanding the impact of each component in a RAG pipeline. Unlike BERGEN, BERGEN-UP is an end-to-end evaluation pipeline that enhanced focuses on the diversity of RAG pipelines and the functionality of each modules.


## ğŸ’ Key Feature
- **BERGEN-UP Pipeline** 
    - *Chunking*
        - token level
            - recall
            - precision
            - iou
    - *Pre-Retrieval*
        - multi-query
        - decomposition
        - hyde
    - *Retrieval*
        - evaluation level
            - precision@k
            - recall@k  
            - f1@k
            - ndcg@k
            - hit_rate@k
            - mrr
    - *Post-Retrieval*
    - *Generation*
        - static metric
            - groundedness
            - answer_relevancy
- **BENCHMARK Pipeline**
    - *Bench-Test*
        - BEIR
        - ASQA
        - TriviaQA
        - HotpotQA
        - WikiQA
        - NQ
- **Extra Module** for RAG
    - Generate Synthetic Dataset
        - QA (= Question Answering)


## ğŸ¥‘ How to run pipeline?

##### 1. Write your evaluation in `conf/config.yaml`

##### 2. Run only below script
```bash
$ uv run pipeline.py label='__experiments_name__'
```

## ğŸŠ Core points Each Module

<details>
<summary>Chunking Module</summary>

- í•µì‹¬ ê¸°ëŠ¥
    - Token Level í‰ê°€
        - Metric : (https://research.trychroma.com/evaluating-chunking)
            - iou
            - precision
            - recall

- ì‚¬ìš©ë²•
    - `conf/config.yaml`ì˜ `chunking` ì„¹ì…˜ì— ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œë‹¤.
    ```yaml
    chunking:
        strategies: 
            - question_set_path: "${hydra:runtime.cwd}/data/chunking/question_set/questions_df_chatlogs.csv"
            - corpora_id_paths:
                chatlogs: "${hydra:runtime.cwd}/data/chunking/corpora/chatlogs.md"
            - Semantic Chunking:
                mode: openai
                embedding_model: "text-embedding-3-large"
                custom_url: "custom_embedding_function_api_address"
            - Recursive Token Chunking:
                chunk_size: 800
                chunk_overlap: 400
            - Fixed Token Chunking:
                chunk_size: 800
                chunk_overlap: 400
    ```

</details>

<details>
<summary>Pre-Retrieval Module</summary>

- í•µì‹¬ ê¸°ëŠ¥
    - LLM-as-a-Judge ê¸°ë°˜ í’ˆì§ˆ í‰ê°€
        - Multi-Query í‰ê°€ ì§€í‘œ:
            - diversity : ìƒì„±ëœ ë‹¤ì¤‘ ì¿¼ë¦¬ë“¤ ê°„ì˜ ë‹¤ì–‘ì„± í‰ê°€ (0-1)
            - coverage : ì›ë³¸ ì¿¼ë¦¬ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ì–¼ë§ˆë‚˜ í¬ê´„í•˜ëŠ”ì§€ í‰ê°€ (0-1)
            - relevance : ìƒì„±ëœ ì¿¼ë¦¬ë“¤ì´ ì›ë³¸ ì¿¼ë¦¬ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€ (0-1)
        - Query Decomposition í‰ê°€ ì§€í‘œ:
            - completeness : ë³µì¡í•œ ì¿¼ë¦¬ë¥¼ ì–¼ë§ˆë‚˜ ì™„ì „í•˜ê²Œ ë¶„í•´í–ˆëŠ”ì§€ í‰ê°€ (0-1)
            - granularity : ë¶„í•´ëœ ì¿¼ë¦¬ë“¤ì˜ ì ì ˆí•œ ì„¸ë¶„í™” ì •ë„ í‰ê°€ (0-1)
            - independence : ê° ë¶„í•´ëœ ì¿¼ë¦¬ê°€ ë…ë¦½ì ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œì§€ í‰ê°€ (0-1)
            - answerability : ë¶„í•´ëœ ì¿¼ë¦¬ë“¤ì´ ì‹¤ì œë¡œ ë‹µë³€ ê°€ëŠ¥í•œì§€ í‰ê°€ (0-1)
        - HyDE (Hypothetical Document Embeddings) í‰ê°€ ì§€í‘œ:
            - relevance : ìƒì„±ëœ ê°€ìƒ ë¬¸ì„œê°€ ì¿¼ë¦¬ì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€ (0-1)
            - specificity : ìƒì„±ëœ ë¬¸ì„œê°€ ì–¼ë§ˆë‚˜ êµ¬ì²´ì ì´ê³  ìƒì„¸í•œì§€ í‰ê°€ (0-1)
            - factuality : ìƒì„±ëœ ë¬¸ì„œì˜ ì‚¬ì‹¤ì  ì •í™•ì„± í‰ê°€ (0-1)
            - coherence : ìƒì„±ëœ ë¬¸ì„œì˜ ì¼ê´€ì„±ê³¼ ë…¼ë¦¬ì  íë¦„ í‰ê°€ (0-1)

- ì‚¬ìš©ë²•
    - `conf/config.yaml`ì˜ `pre_retrieval` ì„¹ì…˜ì— ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œë‹¤.
    ```yaml
    pre_retrieval:
        strategies: 
            - Multi Query:
                path: "${hydra:runtime.cwd}/data/pre_retrieval/multi_query/sample_data.json"
            - Query Decomposition:
                path: "${hydra:runtime.cwd}/data/pre_retrieval/query_decomposition/sample_data.json"
            - HyDE:
                path: "${hydra:runtime.cwd}/data/pre_retrieval/hyde/sample_data.json"
    ```

</details>

<details>
<summary>Retrieval Module</summary>

- í•µì‹¬ ê¸°ëŠ¥
    - Evaluation Level í‰ê°€
        - Metric : 
            - precision@k : ê²€ìƒ‰ëœ ìƒìœ„ kê°œ ê²°ê³¼ ì¤‘ ê´€ë ¨ ë¬¸ì„œì˜ ë¹„ìœ¨
            - recall@k : ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ì¤‘ ìƒìœ„ kê°œ ê²°ê³¼ì—ì„œ ê²€ìƒ‰ëœ ë¹„ìœ¨
            - f1@k : precision@kì™€ recall@kì˜ ì¡°í™”í‰ê· 
            - ndcg@k : ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ëˆ„ì  í• ì¸ ê²Œì¸
            - hit_rate@k : ìƒìœ„ kê°œ ê²°ê³¼ì— ê´€ë ¨ ë¬¸ì„œê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ë¹„ìœ¨
            - mrr : ì²« ë²ˆì§¸ ê´€ë ¨ ë¬¸ì„œì˜ ìˆœìœ„ ì—­ìˆ˜ í‰ê· 

- ì‚¬ìš©ë²•
    - `conf/config.yaml`ì˜ `retrieval` ì„¹ì…˜ì— ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œë‹¤.
    ```yaml
    retrieval:
        strategies: 
            - sample_data_path: "${hydra:runtime.cwd}/data/retrieval/sample_data.json"
            - top_k: 10
    ```

</details>

<details>
<summary>Generation Module</summary>

- í•µì‹¬ ê¸°ëŠ¥
    - G-Eval ê¸°ë°˜ ìƒì„± í’ˆì§ˆ í‰ê°€
        - Metric : 
            - groundedness : ìƒì„±ëœ ë‹µë³€ì´ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì–¼ë§ˆë‚˜ ê·¼ê±°í•˜ëŠ”ì§€ í‰ê°€ (0-1)
            - answer_relevancy : ìƒì„±ëœ ë‹µë³€ì´ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€ (0-1)

- ì‚¬ìš©ë²•
    - `conf/config.yaml`ì˜ `generation` ì„¹ì…˜ì— ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•œë‹¤.
    ```yaml
    generation:
        strategies: 
            - sample_data_path: "${hydra:runtime.cwd}/data/generation/sample_generation_data.json"
            - evaluation_metrics:
                - groundedness
                - answer_relevancy
    ```

</details>
